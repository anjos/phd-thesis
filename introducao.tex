%% Hello emacs, this is -*- latex -*-
\typeout{ ====================================================================}
\typeout{ This is file prefacio.tex, created at 13-Jun-2004 }
\typeout{ Maintained by Andre Rabello dos Anjos <Andre.dos.Anjos@cern.ch> }
\typeout{ ====================================================================}

\chapter{Introdução}
%%\addcontentsline{toc}{chapter}{\numberline{}Pref\'acio}

Sistemas eletrônicos de aquisição de dados são comumente empregados em muitos
campos da engenharia. Exemplos podem ser encontrados na captura de áudio,
vídeo, sinais de satélite, rádio, biológicos e cartográficos dentre
outros. Estes sistemas estão normalmente acoplados à sistemas de deteção, que
buscam pela informação de interesse normalmente embebida em ruído, que deve
ser desconsiderado.

Atualmente, em vários dos problemas, o sistema de deteção de sinais é bastante
complexo, impingindo complexidades também ao sistema de aquisição de dados. O
sistema de deteção captando o sinal de interesse pode estar distribuído em
múltiplas localidades ou requisitar uma velocidade de processamento que torne
impraticável a utilização direta dos produtos disponíveis no mercado. Nestes
casos, é comum também distribuir o sistema de aquisição, combinando-o
posteriormente através módulos de processamento centralizados.

Dependendo do domínio do problema, o sinal adquirido deve ser registrado em
mídia permanente. Em muitos dos casos, porém, nem todos os sinais coletados
são suficientemente interessantes para que sejam registrados. Nestas
situações, sistemas de filtragem \eng{online} podem ser empregados para
disparar o processo de gravação no momento em que se disponibilizam os sinais
de interesse. Da mesma forma, dependendo do sistema de deteção e aquisição,
estes sistemas podem ter que enfrentar parâmetros de operação bastante
rigorosos. O volume dos dados a ser discriminado poderá ser grande o
suficiente, ou ocorrer em intervalos de tempo curtos o suficiente, que exijam
a distribuição do processamento também no sistema de filtragem.

O processo de discriminação empregado no sistema de filtragem está diretamente
relacionado aos dados sendo adquiridos: os sinais interessantes podem ser
identificáveis através de operações simples sobre sinal coletado ou poderão
exigir um pré-processamento para que seja extraído um conjunto de parâmetros
que simplifiquem o processo de classificação. Nestes casos, é comum empregar
compressão ou compactação dos sinais de entrada do sistema de filtragem para
que se reduza a dimensionalidade do espaço de dados a ser analisado. A
informação a cada análise poderá ainda estar segmentada, o que traz
complexidade adicional ao sistema de processamento de dados. Após a
compactação, compressão ou ambos, é possível que o problema ainda se encontre
em um espaço com dimensionalidade bastante elevada. 

Em situações deste gênero, a classificação exigirá técnicas avançadas para a
identificação dos sinais. Redes Neurais Artificiais vem sendo utilizadas em
muitos problemas nesta área, tanto como forma de compressão dos sinais de
entrada como classificadores, atingindo excelentes níveis de classificação
para igualmente ótimos patamares de desempenho. Redes Neurais são mecanismos
de simples implementação e possuem eficiência comprovada em vários domínios
distintos.

Neste trabalho, apresenta-se uma aplicação onde todos os níveis de
complexidade descritos anteriormente serão exigidos. Neste caso, o sistema de
deteção produzirá eventos em pulsos separados por 25 nanossegundos, a massa de
dados a cada evento estará na ordem de alguns \eng{megabytes} e, a taxa de
eventos de interesse será de apenas alguns para dezenas de milhões.

\section{Motivação}

Experimentos em Física de Altas Energias procuram por confirmações
experimentais dos modelos propostos nos estudos teóricos. Laboratórios deste
domínio da Física contam com um sistema de colisão, que provoca o aparecimento
da física de interesse, associado a complexos sistemas de deteção, que
registram a evolução no tempo de cada evento produzido. Naturalmente
envolvidos no processo de deteção, encontram-se sistemas eletrônicos que
automatizam a busca, registro e análise dos resultados obtidos.

Dada a natureza complexa e rara dos fenômenos estudados em muitos destes
experimentos, a física de interesse está normalmente submersa em uma
gigantesca massa de eventos que representam ora ruído, provocados pelo mal
funcionamento dos sistemas de deteção e colisão, ora eventos ordinários, já
bastante estudados no passado. Em específico, em experimentos que buscam a
confirmação de canais físicos em patamares energéticos elevados, de alguns
gigaelétron-volts para cima, a taxa de eventos que representa canais
desinteressantes contra a de eventos que possam interessar pode estar na faixa
de 10$^6$ para 1. Desta forma, os eventos de interesse aparecem escondidos no
meio de milhões de outros eventos ordinários, ou que representam apenas
ruído. Ademais, para que se consiga apreciar a Física de interesse, milhões de
eventos são gerados por base de tempo para que se colete estatística
suficiente para a comprovação do canal estudado. O volume de dados associados
a cada evento vem aumentando, junto com a ambição dos experimentos. Novos
sistemas de deteção exigem alguns \eng{megabytes} para cada evento registrado,
o que representa uma dificuldade extra na realização destes experimentos.

Para resolver este problema, introduzem-se sistemas eletrônicos de filtragem
que podem selecionar, de forma \eng{online}, os eventos de interesse dos
eventos que representam ruído ou física ordinária. Estes sistemas são por
vezes tão complexos quanto os detetores do experimento e contam com soluções
elegantes para os diversos problemas de transmissão e seleção de
dados. Soluções atuais empregam forte paralelização e técnicas modernas de
processamento de sinais para responder às demandas destes experimentos.

Redes Neurais Artificiais vem sendo empregadas como solução em sistemas de
filtragem em vários experimentos. Dada a forte segmentação dos dados nos
detetores, os sistemas neurais conseguem compactar e extrair as informações
vitais para a discriminação dos dados, mantendo não só a alta qualidade de
classificação como também excelentes níveis de desempenho.

\section{O experimento ATLAS e o bóson de Higgs}

A deteção do bóson de Higgs é um dos grandes expoentes da Física de Altas
Energias atual. Esta partícula, se existir, possui uma massa bastante elevada
(centenas de gigaelétron-volts) e se apresenta como um canal bastante raro e
de difícil reprodução laboratorial. A descoberta desta partícula confirmará
mais uma vez o Modelo Padrão, já bastante testado, inicialmente proposto em
1954.

O CERN, na Suíça, é o local onde está sendo desenvolvido o experimento ATLAS,
que pretende investigar a rara física do bóson de Higgs. O experimento
utilizará colisões próton-próton, numa taxa de 40 milhões por segundo para
conseguir obter alguns destes bósons por dia de operação. As colisões serão
providas pelo Grande Colisionador de Hádrons (do inglês \eng{Large Hadron
Collider}, LHC), que será, quando estiver operacional, o mais potente no
mundo, podendo colidir prótons com 14 TeV no centro de massa.

Uma vez que cada evento no ATLAS consumirá cerca de 1,5 \eng{megabytes} de
espaço em memória, um dos problemas do projeto e construção do experimento
está na articulação de um sistema de filtragem de eventos que seja capaz de
fazer uma seleção \eng{online} dos eventos que representem a Física de
interesse.

O Sistema de Filtragem do ATLAS foi inicialmente projetado para operar em três
níveis conectados em cascata com complexidade, qualidade de deteção e tempo de
operação por evento, crescentes. O Segundo Nível de Filtragem (LVL2), em
específico, será constituído de cerca de 1.000 unidades de processamento
ligadas em rede, processando cada um evento completo aprovado pelo Primeiro
Nível (LVL1). Cada evento terá, em média, aproximadamente 10 milissegundos
para ser processado.

O LVL2 coordena um conjunto de algoritmos descritos em \eng{software} que
executa a seleção de eventos. Dentre esses, algoritmos de discriminação
elétron/jato têm papel fundamental na eficiência da aquisição de dados, uma
vez que a ocorrência de elétrons pode representar a Física de interesse. Neste
caso, elétrons representam o sinal de interesse a ser detetado. Estima-se que,
a cada 25.000 candidatos à elétrons definidos pelo LVL1, apenas 1 será
verdadeiramente um elétron. Cabe ao LVL2 a redução deste ruído de fundo na
deteção de elétrons.

A informação para a deteção pode ser obtida do sistema de leitura do detetor
usando-se as primitivas do complexo \eng{software} de base do sistema de
filtragem, disponível em cada unidade de processamento dentro do LVL2. Os
dados para cada candidato à elétron são formados por células de deteção
segmentadas tanto da direção de penetração da partícula, quanto no plano de
interseção. Este sistema forma uma malha de elementos que contém amostras da
energia de interação do objeto com o sistema de deteção, ao longo de sua
trajetória. No total, cada objeto a ser avaliado pelo LVL2, disporá de cerca
de 1.300 células de deteção.

O processo de discriminação é dividido em duas etapas bem definidas: a
extração de características ou pré-processamento e a deteção propriamente
dita. A extração de características visa a compactação do sinal a ser detetado
de forma que se realcem as propriedades necessárias a deteção e reduza-se o
espaço de entrada. A deteção propriamente dita, neste caso, deverá ser simples
e robusta de forma que o canal de interesse se exprima claramente mesmo que
embebido no rúido de fundo. 

\section{Sobre as origens deste trabalho}

Este trabalho teve seu início em 1995 com o Projeto Final de gradução
``Sistema de classificação baseado em uma máquina com sistema distribuído'',
por este autor, apresentado em setembro de 1997. O experimento ainda estava
sendo desenvolvido e havia pouca ou quase nenhuma informação disponível do
sistema de deteção, que provê os dados para a deteção das
partículas. Tampouco, do Sistema de Filtragem, que estava em vias de
desenvolvimento. A arquitetura final deste sistema ainda não havia sido
escolhida.

Com base nas escolhas disponíveis na época, desenvolveu-se um sistema de
filtragem para o LVL2 baseado em um processamento distribuído, comandado por
um nó central de processamento, chamado Supervisor. As unidades de
processamento ou nós-escravos eram pré-carregadas com um sistema de deteção
neural. Estes nós analisavam os dados de cada evento atribuído pelo Supervisor
e distingüia, \eng{online}, se o evento era interessante e deveria ser
aprovado por este nível de filtragem. No conjunto de dados disponível na
época, as características (após compactação) de cada objeto analisado já
haviam sido calculadas e portanto o sistema desenvolvido limitava-se ao papel
de \textit{deteção propriamente dita}, como colocado anteriormente.

Neste caso, o Supervisor alocava, em \eng{round-robin}, os eventos a cada uma
das unidades de processamento, que utilizavam o sistema neural para avaliar as
características de um objeto, determinando se o evento deveria ser aprovado ou
rejeitado. A resposta era enviada de volta ao Supervisor, que simplesmente a
registrava em um arquivo de saída. No final do processamento, a saída
registrada pelo Supervisor era comparada aos valores obtidos com um programa
\eng{offline} para que se determinasse se o sistema estava operando
corretamente.

Este modelo foi implementado em um máquina como 16 nós de processamento tipo
\eng{INMOS Transputer T-9000@40~MHz}, da companhia Telmat. Estes nós eram assim
chamados pois cada um continha uma unidade rápida de processamento acoplada
uma interface de rede especializada, com 4 canais independentes de
comunicação. O formato da interconexão entre os nós era configurável e foi
adapatado ao problema da distribuição dos dados entre o Supervisor e as
Unidades de Processamento. Para executar o \eng{boot} desta máquina, a
configuração de interconexão era carregada através de um sistema hospedeiro,
em seguida um \eng{micro-kernel} e, por final, um programa a ser
executado. Este programa podia ser codificado em C e compilado em um PC de
forma cruzada, para que fosse executado nos \eng{transputers}.

Para esta implementação, o menor tempo de processamento para cada evento foi
390 microssegundos. O sistema de distribuição de eventos em
\eng{round-robin} garantia que 9 dos 15 nós de processamento estaria
executando uma tarefa dada um instante tempo, o que era apenas sub-ótimo tendo
em vistas as capacidades da máquina.

Com o passar dos anos, os diversos sistemas de deteção do experimento
começaram a se definir de forma mais concreta e os programas de simulação de
eventos físicos a ganhar detalhes e se aproximar, cada vez mais, de sua forma
atual. De posse de dados simulados de calorimetria relativos ao processamento
no LVL2, desenvolveu-se, de 1999 a 2000, o trabalho que culminou na
dissertação de mestrado entitulada ``Sistema neuronal rápido de decisão
baseado em calorimetria de altas energias''.

Os dados disponíveis nesta época representavam cerca de 270 elétrons e 3600
jatos simulados através de interações simples com o detetor. O conjunto de
dados foi obtido à partir de uma simulação primitiva do sistema de deteção do
ATLAS e não continha diversos dos elementos que estarão presentes no sistema
de deteção final, tais como efeitos de ruído, empilhamento, variação de
granularidade e variação de energia.

A partir deste conjunto de dados, desenvolveu-se um sistema de discriminação
neural que pudesse operar dentro do Segundo Nível de Filtragem do ATLAS. Este
discriminador utilizava um pré-processamento em forma de anéis que se
aproveita do padrão de interação de elétrons com o detetor. Ao invés de
compactar o sinal da interação de elétrons com o detetor formando apenas 4
variáveis, como sugeria o sistema empregado no CERN àquela época, 58 variáveis
(anéis) eram produzidas. Um sistema de normalização simplificado, baseado na
energia total do objeto, foi empregado de forma que se removesse qualquer
polarização provocada pelas pequenas variações de energia total observadas nos
dados.

O resultado da extração de anéis, normalizado, era utilizado como entrada para
uma detetor neural com 58 neurônios de entrada, 5 neurônios na camada
escondida e apenas uma saída que indicava se o objeto na entrada era um
elétron ou não. A rede neural era treinada de forma supervisionada,
utilizando-se metade do conjunto de dados disponível. Neste caso, obteve-se
95\% de eficiência na deteção de jatos contra 97\% para a deteção de
elétrons. Este resultado foi comparado com uma análise simplificada do sistema
de deteção desenvolvido no CERN, que apontava uma capacidade de discriminação
de 95\% para elétrons para um falso-alarme de 11,6\% para jatos.

Uma análise baseada no impacto de cada um dos 58 anéis na saída da rede neural
(análise de relevância) revelou que era possível utilizar apenas 20 dos 58
anéis iniciais para uma deteção marginalmente inferior apenas àquela
utilizando todos os anéis, mas ainda muito superior à análise proposta no
CERN. Uma implementação simplificada do algoritmo foi executada, indicando a
possibilidade de ser utilizado no LVL2.

Atualmente dispõe-se de um sistema muito mais elaborado para a simulação do
detetor ATLAS, e das colisões que acontecerão quando o acelerador for
finalmente ligado, em meados de 2008. Dentre os novos elementos presentes, se
encontram:

\begin{itemize}
\item Dimensão flutuante para os dados utilizados para a deteção. No caso do
estudo para a dissertação de mestrado, limitou-se o escopo da análise a dados
com granularidade constante. Uma simulação muito mais realística do sistema de
deteção do ATLAS está presente na nova massa de dados;

\item Introdução de ruído relativo ao sistema de deteção. Este efeito não
estava presente nos dados obtidos anteriormente, mas estará certamente
presente quando o experimento estiver operacional. A adição de ruído aos
sistemas de deteção diminui a acuidade das medidas introduzindo uma
perturbação não desprezível aos algoritmos de deteção;

\item Um volume maior de dados está disponível para este trabalho, o que
possibilita uma análise muito mais detalhada e acurada do problema de deteção
elétron/jato. Enquanto que para os trabalhos anteriores dispunha-se de uma
massa muito limitada de dados, para este trabalho dispõe-se de aproximadamente
30.000 objetos (cerca de 22.500 elétrons e 7.500 jatos) para análise, o que
diminui a margem para possíveis erros estatísticos introduzidos por uma
análise sobre um conjunto de dados limitado;

\item A infrastrutura de suporte para o sistema de filtragem está
disponível. Todos os resultados, tanto de desempenho físico quanto velocidade
de processamento devem ser mencionados com relação a uma implementação
compatível e estável dentro deste ambiente. Desta forma é possível fazer o
sistema de deteção operar tal qual um algoritmo de deteção operaria no sistema
de filtragem e comparar seu desempenho tendo em vistas todos os parâmetros
funcionais deste complexo ambiente;

\item O algoritmo empregado atualmente no CERN está também disponível em um
formato em que seja possível uma comparação direta em termos de eficiência e
desempenho com um sistema alternativo. De posse dos resultados de cada um dos
algoritmos é possível conduzir uma análise mais detalhada das diferenças entre
os dois sistemas.
\end{itemize}

\section{A contribuição deste trabalho}

Enquanto que durante os estudos que culminaram na dissertação de mestrado
indicada anteriormente tenham sido baseados em uma massa de dados menos
realística com relação às condições finais do experimento, desenvolveu-se a
base de um sistema de deteção bastante eficaz que foi re-utilizado neste
trabalho para propor um sistema completo de discriminação elétron/jato que
atendesse a todos os pré-requisitos do complexo sistema de filtragem do
ATLAS. Neste duro ambiente, os recursos computacionais são extremamente
limitados, pois cada evento no LVL2 deve ser executado em média, em um tempo
inferior a 10~milissegundos. Este tempo de processamento encompassa tanto o
acesso aos dados localizados do outro lado de uma rede Ethernet, no sistema de
leitura do detetor, quanto o processamento dos dados em si, incluindo o
pré-processamento dos elementos de deteção (calibração e organização dos
dados), a extração de características e a deteção propriamente dita. Múltiplos
algoritmos serão executados neste espaço de tempo, caso o evento seja aprovado
e, portanto, o tempo disponível para cada algoritmo é normalmente definido
como ``o menor possível''. O sistema deve ainda ser programado em uma
linguagem de alto-nível (C++), o que torna o problema ainda mais complexo,
tendo em vistas os tempos de processamento-alvos.

O trabalho foi desenvolvido tanto CERN e na UFRJ, no contexto da colaboração
internacional entre estes dois centros de pesquisa. Dentro desta colaboração,
contribuiu-se com o desenvolvimento e construção de boa parte do Segundo Nível
de Filtragem e sua infrastrutura. Dentre as contribuições mais significativas,
podemos destacar:

\begin{enumerate}
\item Desenvolvimento e aplicação da Unidade Central de Processamento no
LVL2, a L2PU;
\item Desenvolvimento e aplicação da biblioteca global de formatação de dados
do ATLAS (\eng{eformat});
\item Desenvolvimento e aplicação do \eng{Pseudo} Sistema de Leitura (PROS);
\item Desenvolvimento e aplicação de uma biblioteca para rápido acesso e
processamento de dados de calorimetria;
\item Desenvolvimento e aplicação da camada de \eng{software} que combina a
L2PU e a suíte de processamento \eng{offline} Athena;
\item Medidas de desempenho do sistema de filtragem para diferentes cenários,
com ou sem a utilização de algoritmos de discriminação.
\end{enumerate}

O sistema de deteção propriamente dito foi desenvolvido em seguida. Para tal,
utilizou-se o conjunto de dados de perfil complexo descrito anteriormente. Com
base nesta massa, conduziu-se uma análise detalhada do comportamento dos
algoritmos de extração de características (compactação da informação de
entrada) e de deteção propriamente dita, atualmente empregado no LVL2 para a
análise elétron/jato. Este algoritmo de compactação e deteção é baseado no
conhecimento especialista, que determina variáveis altamente discriminantes
tendo por base a Física de interesse que se deseja observar.

Nesta análise, e levando-se em conta a massa de dados disponível,
determinou-se a eficiência de discriminação em 91,85\% para elétrons para um
falso-alarme de 10,19\% em jatos. Uma análise mais apurada das variáveis
produzidas por este sistema indica que as variáveis especialistas são
altamente descorrelacionadas e altamente relevantes à deteção. Com base no
valor canônico de deteção observado com a análise do sistema atual de
discriminação, desenvolve-se um detetor neural para as variáveis
especialistas. Este detetor neural tem um resultado equivalente ao sistema de
deteção atualmente empregado no ATLAS. Uma análise de componentes
independentes também mostra que as variáveis usadas para discriminação são,
praticamente, ortogonais entre si.

Conduz-se então uma análise baseada no pré-processamento em anéis. Para esta
análise, um novo sistema de mapeamento das informações do detetor em anéis foi
elaborado, levando-se em consideração dois aspectos que ainda não haviam sido
abordados: a problemática dos dados faltantes e a introdução de ruído
proveniente da eletrônica. Com base neste pré-processamento, 100 variáveis
correspondentes aos anéis são extraídas de cada objeto a ser analisado. Um
detetor neural é elaborado para a fase de deteção propriamente dita,
levando-se em consideração uma otimização do espaço de parâmetros para seu
treinamento. Este novo sistema obtém uma eficiência de classificação de
elétrons de $96,55$\% contra apenas $3,12$\% de falso-alarme. Uma análise de
relevância baseada das variáveis de entrada (anéis) ao detetor neural é
conduzida tendo em vistas seu poder discriminante ao invés de baseado em
variações do erro médio quadrático, como em trabalhos anteriores.

Finalmente, e para que possa ser operado dentro do sistema de filtragem do
ATLAS, descreve-se uma implementação completamente compatível com a atual
infra-estrutura. Testes de performance e exatidão são conduzidos em várias
plataformas, donde se conclui que o sistema baseado em anelamento e deteção
neural seja viável para implementação no segundo nível de filtragem do
experimento. Enquanto o sistema atual empregado no CERN consome cerca de 3,64
milissegundos para ser executado, o sistema baseado na extração em anéis e
deteção neural, mais que 3 vezes mais eficiente na rejeição de
falsos-positivos, é executado em 3,8 milissegundos dentro da mesma
infraestrutura de base, apenas cerca de 150 microssegundos de diferença em
média.

\section{Organização do Texto}

O Capítulo~\ref{chap:introducao} traz uma visão geral da Física de Partículas
atual. Este capítulo inicia-se sumarizando fatos histórios que culminaram na
formulação do Modelo Padrão para a descrição das interações sub-atômicas. Em
seguida, é feita uma revisão das técnicas de aceleração e deteção de
partículas mais comuns em experimentos nesta área. Na
Seção~\ref{sec:calorimetria} descrevem-se detetores conhecidos como 
\textit{calorímetros} em maiores detalhes. Aqui, discutem-se as partículas de
interesse para o trabalho e a forma como interagem com este tipo de detetor. O
capítulo termina introduzindo noções gerais sobre os sistemas de filtragem que
equipam os experimentos modernos.

O Capítulo~\ref{chap:atlas} narra especificidades do experimento ATLAS, que
investigará a Física do bóson de Higgs. O capítulo é encabeçado por um breve
histório do CERN, adentrando por detalhes operacionais do experimento e do
colisionador LHC, que gerará as interações próton-próton necessárias. A
Seção~\ref{sec:atlas-calo} traz um resumo das características operacionais dos
Calorímetros do ATLAS e um conjunto de referências para maiores detalhes.

O Sistema de Filtragem do ATLAS é introduzido no
Capítulo~\ref{chap:trigger}. Este capítulo descreve todos os sub-sistemas que
compõem o Sistema de Filtragem do experimento, desde o Primeiro Nível de
Filtragem até chegar à gravação de um evento selecionado em mídia
permanente. É neste ambiente que são executados os algoritmos de filtragem
abordados neste trabalho. O Segundo Nível de Filtragem é detalhado a partir da
Seção~\ref{sec:lvl2arch}. Resultados obtidos durante simulações do
comportamento desta parte do sistema são apresentados na
Seção~\ref{sec:lvl2work}. O final deste capítulo é dedicado ao ambiente de
processamento de dados Athena e sua interação com o Sistema de Filtragem do
ATLAS. Neste capítulo descreve-se em detalhes os componentes de infraestrutura
produzidos no contexto da colaboração entre o CERN e a UFRJ.

%\textit{[ Faltando material relativo à re-organização dos capítulos 5, 6 (e futuro) 7 ]}

O Capítulo~\ref{chap:conclusions} traz uma conclusão dos estudos realizados
até o momento presente e apresenta extensões de estudo para este trabalho.

Para a melhor compreensão dos termos utilizados na descrição da geometria dos
objetos estudados neste trabalho, o Apêndice~\ref{ap:coord} introduz o sistema
de coordenadas do ATLAS. O Apêndice~\ref{ap:published} traz um resumo da
produção científica no período e projetos que integram o corpo deste estudo. O
Apêndice~\ref{ap:framework} sumariza os detalhes de implementação do
pacote de \eng{software} \texttt{Neuralringer}, utilizado para as medidas de
eficiência, relevância e que foi transplantado para operação dentro do sistema
de filtragem do experimento.

\typeout{ *************** End of file prefacio.tex *************** }

%% Hello emacs, this is -*- latex -*-
\typeout{ ====================================================================}
\typeout{ This is file conclusao2.tex, created at 28-Nov-2006 }
\typeout{ Maintained by Andre Anjos <Andre.dos.Anjos@cern.ch> }
\typeout{ ====================================================================}

\chapter{Conclusões}
\label{chap:conclusions}

O Sistema de Filtragem do experimento ATLAS, no CERN, oferece um ambiente
desafiador a seus sistemas de deteção. A taxa de eventos na entrada do LVL2 é
bastante alta, na ordem de 100 mil por segundo. O sinal de interesse é um
evento raro, apresentando-se escondido em uma massa de eventos ordinários
também bastante alta, na ordem de 1 para $10^9$. O sistema é construído de
forma altamente distribuída. Os dados utilizados na deteção são transferidos
através de uma rede às unidades de processamento que, por sua vez, devem
rapidamente ($10$ ms) responder com um sinal de rejeição, na maioria dos
casos, ou aceitação.

A deteção elétron/jato representa um dos estudos mais importantes de
decaimento da rara Física do bóson de Higgs. O processo de discriminação de
elétrons é conduzido, inicialmente, por uma confirmação baseada em
calorimetria. Os dados de cada região de interesse (RoI) destacada pelo
Primeiro Nível de Filtragem são (lentamente) descarregados e tratados nas
Unidades de Processamento do LVL2, deixando pouco tempo de processamento para
a operação dos algoritmos de deteção propriamente ditos. Os dados de uma RoI
estão organizados de forma altamente granular e segmentada, favorecendo a
deteção através da análise do perfil de deposição energética da partícula ao
longo de sua trajetória. A granularidade, segmento a segmento, varia ao longo
dos eixos do detetor, podendo cruzar regiões totalmente desprovidas de células
de deteção. Cada RoI, em média, é composta de mais de 1.000 células.

A Unidade de Processamento do LVL2 foi desenvolvida tendo por base a
maximização da utilização dos recursos computacionais pelos algoritmos de
deteção, funcionando em múltiplas tarefas de processamento. Uma interface de
``cola'' foi criada entre o ambiente \eng{online}, onde eventos fluem pela
rede do Sistema de Filtragem e o ambiente \eng{offline}, onde os algoritmos
são desenvolvidos e testados. Essa unidade foi testada com relação a sua
robustez e confiabilidade, tendo passado aos diversos critérios necessários a
seu emprego no Sistema de Filtragem. Testes apontam que seja possível um
modelo de desenvolvimento de algoritmos baseado nestes preceitos: criação
\eng{offline}, aplicação \eng{online}. Neste ambiente, os diversos algoritmos
que devem ser executados no Sistema de Filtragem são desenvolvidos de forma
desacoplada e re-acoplados durante a execução combinada do sistema.

A execução dentro dos Altos Níveis de Filtragem é modelada sempre
distinguindo-se a fase de Extração de Características (Fase 1) e Hipótese
(Fase 2), que tem sua execução agendada, uma após a outra, complementando-se,
mas guardando sua independência. O algoritmo T2Calo é provido atualmente como
implementação de referência para a Fase 1. Esse sistema altamente depurado ao
longo de muitos anos de desenvolvimento compacta a dimensão de entrada ao
detetor elétron/jato em apenas 4 variáveis altamente discriminantes. As
variáveis desse sistema não são linearmente separáveis, mas apresentam bom
grau de classificação quando utilizam-se classificadores baseados em cortes
uni-dimensionais sucessivos (sinal $91,85\%/10,19\%$ falso alarme) ou lineares
(sinal $90,77\%/9,79\%$ falso alarme). A adição de mais variáveis à saída do
T2Calo tende a melhorar a qualidade de deteção que pode ser obtida com esse
método de compactação.

A compactação por anéis de deposição energética é uma implementação
alternativa para o processo de Extração de Características (Fase 1) que
aproveita-se do perfil de deposição energética das partículas que interagem
com calorímetros. Esta técnica evoluiu com o experimento, suas modificações e
a melhoria de sua simulação, mantendo-se simples e eficaz. Desenvolvemos uma
implementação de referência para a extração baseada em anéis que é
suficientemente rápida (podendo ser executada em até 125 $\mu$s de forma
desacoplada), resolvendo os problemas de variação de granularidade, dados
faltantes e carência de sensores nas regiões de \eng{crack} de forma
igualmente eficiente e flexível. Ao passo que simplifica a Fase 1 do
processamento das RoI's de candidatos a elétrons, essa técnica introduz um
conjunto de variáveis (25 vezes) maior que aquele provido pelo T2Calo.

A técnica de compactação por anéis é desenvolvida baseando-se no pico de
deposição energética obtido no LVL2 e, portanto, é independente da precisão de
deteção do LVL1. O critério de normalização empregado varia com a energia do
objeto analisado, apresentando-se muito eficaz em praticamente todo o espectro
de energia considerado, como nos mostra a
Figura~\ref{fig:ringer-efficiency-et}.

A segunda fase do processamento de uma RoI é a deteção do objeto analisado,
sendo realizada após a compactação. A implementação de referência do ATLAS é
baseada em uma análise de cortes uni-dimensionais (EGammaHypo), de difícil (e
longa) calibração, requerendo a intervenção especialista freqüentemente. Em
contrapartida, se propõe a utilização de Redes Neurais Artificiais (RNA's)
como forma de se melhorar a eficiência de deteção de elétrons no LVL2. O
emprego de classificadores, que tentam encontrar correlações de ordens mais
elevadas, é necessária nesse ambiente uma vez que:

\begin{enumerate}
\item O problema se apresente de uma forma linearmente inseparável;
\item O nível de correlação entre as 4 variáveis utilizadas para deteção é
baixo.
\end{enumerate}

Redes neurais podem ser empregadas tanto acopladas às saídas do T2Calo quanto
às somas em anéis proposta, permitindo maiores níveis de eficiência na deteção
de elétrons em ambos os casos. Quando associadas à compactação provida pelo
T2Calo aos dados de uma RoI, RNA's podem melhorar o desempenho de
classificação comparado a sistemas lineares de classificação, atingindo
92,38\% de deteção contra 9,05\% de falso-alarme. Considerando-se as demais
saídas disponíveis neste algoritmo de compactação, é possível atingir níveis
ainda mais altos: 94,79\% de deteção contra apenas 7,93\% de falso-alarme. Um
estudo da ortogonalidade deste conjunto de 14 variáveis (Análise de
Componentes Principais) revela que não há correlação direta que seja
importante ao sistema de deteção.

Quando associadas ao compactador utilizando anéis de deposição energética,
RNA's conseguem melhorar a relação sinal-ruído substanciosamente, podendo
atingir uma eficiência de classificação de 96,89\% contra apenas 2,93\% de
falso-alarme. Comparativamente à dupla T2Calo/EGammaHypo, estes números
representam um decréscimo de 3 vezes na taxa de jatos que seria aprovada ao
demais níveis de filtragem. Um conjunto de análises apoia os resultados de
eficiência, demonstrando que a utilização desta versão desenvolvida da soma em
anéis à classificadores neurais, está livre de tendências com relação à
localização do objeto ou seu valor energético, apresentando-se igualmente
eficaz em uma multitude de intervalos.

Uma Análise de Relevância baseada no poder de classificação dos detetores
(produto SP), ao invés do desvio no EMQ, é também conduzida. Esta análise pode
ser utilizada como uma ferramenta de poda, para gerar classificadores mais
compactos ou como um simples teste de robustez para sistemas de deteção. De
acordo com uma comparação a sua análoga baseada no EMQ, apresentou-se mais
poderosa na escolha de variáveis que, pela poda, minimizam o impacto na
classificação.

Em alguns casos, esta análise também indica elementos que estejam prejudicando
o poder classificatório de um detetor. Resultados (marginalmente) melhores na
classificação, na ordem de alguns pontos percentuais, puderam ser obtidos
baseando-se em podas conduzidas através da relevância de discriminação.

Finalmente, demonstrou-se que a metodologia proposta para o Sistema de
Filtragem (desenvolvimento \eng{offline}, aplicação \eng{online}) funciona
adequadamente, caso o desenvolvedor respeite critérios como tempo de execução
e uso de recursos computacionais. Pacotes que implementam as Fase 1 e 2 de
deteção elétron/jato, baseada em anéis e RNA's foram migrados para dentro do
ambiente Athena. Enquanto, de forma desacoplada, é possível executar a
deteção em tempos que variam de 100 a 500 microssegundos, dependendo da
configuração dos anéis e das plataformas de execução, quando incorporados ao
pesado ambiente de desenvolvimento do ATLAS, as mesmas instruções são
executadas em cerca de 4 milissegundos.

Estes tempos de processamento são compatíveis com outros sistemas atualmente
empregados no LVL2, inclusive com a dupla T2Calo/EGammaHypo, que consegue
processar RoIs em um tempo equivalente, aproximadamente 3,6 milissegundos. A
implementação baseada na infraestrura do Sistema de Filtragem pode ser
executada tanto \eng{offline} quanto \eng{online}, totalmente conectada ao
sistema de leitura do detetor e de controle do experimento.

Uma implementação do sistema de anelamento e deteção neural, baseada em DSP's
SHARC da Analog Devices, é derivada das mesmas bibliotecas como plataforma de
desenvolvimento adicional. Esta implementação indica a portabilidade do
algoritmo, que pode ser executado, igualmente, em cerca de 4 milissegundos
dentro desta plataforma.

\section{Linhas de Pesquisa}

A Análise de Componentes Principais (ACP), aplicada ao problema da separação
elétron/jato através dos dados de uma RoI ou através da informação de anéis,
foi abordada em uma tese de doutorado \cite{herman}, com bons resultados. Este
sistema propõe um compactador (Fase 1) baseado na correlação entre os valores
de energia de cada célula de uma RoI ou, ainda, entre seus anéis de deposição
energética. Resultados indicam que a utilização de uma grande quantidade de
sensores dificulte a análise estatística devido ao grande número de graus de
liberdade na formulação do compactador. A ACP, quando extraída diretamente dos
anéis de deposição energética, mostra-se mais eficiente e de simples
aplicação.

A Análise de Componentes Independentes (ACI) representa uma extensão da
Análise de Componentes Principais \cite{oja-ica}. Desta vez, no lugar de se
procurar uma transformação linear que descorrelacione os dados no novo espaço,
deseja-se computar a transformação linear na qual as variáveis do espaço
transformado sejam independentes. Esta é uma premissa muito mais forte que
a simples descorrelação.

Uma das pré-condições para a ACI é de que o ruído introduzido pelo sistema no
sinal de análise seja branco e gaussiano. Esta é, no entanto, uma hipótese
bastante razoável em experimentos de Física de Altas Energias \cite{knoll,
leo}. A ACI pode ser conduzida utilizando-se diversos métodos que deverão ser
avaliados com relação a sua velocidade e qualidade. Espera-se que esta técnica
possa relevar informações no padrão de interação das partículas com os
calorímetros do ATLAS, que estão mascarados nos anéis de deposição energética,
aumentando, assim, a qualidade da discriminação conduzida no LVL2.

O conjunto de componentes extraídas não poderá ser organizado, \textit{a
priori}, como acontece no caso da Análise de Componentes Principais, já que
não há uma correlação evidente entre os coeficientes da transformação e sua
importância. Neste caso, outros métodos, como o método da relevância de
discriminação introduzido neste trabalho, poderão ser explorados para que se
atinja a compactação dos dados de entrada.

Na mesma linha de pesquisa, a utilização de uma ACP não-linear pode também
revelar correlações não-lineares que não puderam ser observadas neste trabalho
ou em \cite{herman}.

Métodos de treinamento mais sofisticados podem ser também introduzidos no
sistema atual de deteção (Fase 2), aumentando a qualidade do treinamento,
tempo de convergência e a robustez do sistema de discriminação final. Em
especial, técnicas mais modernas, como redes neurais qüânticas \cite{qnns} ou
menos exploradas neste contexto, como máquinas de vetor de suporte,
\cite{haykin} podem ser pensadas como alternativas interessantes, oferecendo
melhor robustez ao ruído e a casos de empilhamento (\eng{pile-up}).

A compactação baseada na soma em anéis de deposição energética pode ser
explorada de forma a ser maximizada. Novas combinações devem ser exploradas
tendo em vista a quantidade de dados que devam ser lidas do sistema de
leitura do detetor e o fator de compactação propriamente dito. Especificamente,
a técnica de normalização dos dados poderia ser ajustada tendo em vista os
resultados da análise de relevância.

A deteção baseada em anéis pode também ser utilizada para análise e
reconstrução \eng{offline}. O sistema de deteção desenvolvido neste trabalho
deve ser readaptado para trabalhar neste ambiente. Comparativos diretos com as
técnicas atuais de reconstrução poderão ser feitos. Métodos de análise
estocástica são bastante difundidos e utilizados atualmente nesta sub-área da
Física de Altas Energias.

Finalmente, seria possível expandir a utilização da técnica de anelamento para
outras assinaturas interessantes, filtráveis por uma análise calorimétrica,
tais como $H \rightarrow \gamma + \gamma$ ou, ainda, na separação
$\gamma/\pi^0$, tanto \eng{online} como \eng{offline}.

\typeout{ *************** End of file conclusao2.tex *************** }
